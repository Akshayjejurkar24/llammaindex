ğŸ“„ PDF RAG API â€” FastAPI + LlamaParse + Qdrant + OpenAI

Upload PDFs â†’ Parse â†’ Chunk â†’ Embed â†’ Store â†’ Query using RAG

This project provides a simple Retrieval-Augmented Generation (RAG) pipeline using:

FastAPI â€“ API framework

LlamaParse â€“ PDF parsing to Markdown

LlamaIndex â€“ chunking + embeddings + vector retrieval

Qdrant â€“ vector database

OpenAI â€“ embeddings + LLM answering

ğŸš€ Features

âœ” Upload PDF documents
âœ” Parse to Markdown using LlamaParse
âœ” Chunk using SentenceSplitter
âœ” Generate embeddings with text-embedding-3-large
âœ” Store embeddings in Qdrant
âœ” Query documents with GPT-4o using RAG
âœ” Simple and extendable API endpoints

ğŸ“¦ Installation
1. Clone the repository
git clone https://github.com/your-username/pdf-rag-api.git
cd pdf-rag-api

2. Create a virtual environment
python3 -m venv venv
source venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

ğŸ”‘ Environment Variables

Create a .env file in the root directory:

QDRANT_URL=https://your-qdrant-instance-url
QDRANT_API_KEY=your_qdrant_api_key
OPENAI_API_KEY=your_openai_api_key
LLAMAPARSE_API_KEY=your_llamaparse_api_key


âš ï¸ Make sure your Qdrant collection allows vectors with the embedding size of 3072 (text-embedding-3-large).

â–¶ï¸ Run the API

Start the server:

uvicorn main:app --reload


API will be available at:

http://localhost:8000


Interactive Swagger docs:

http://localhost:8000/docs

ğŸ“¤ Upload PDF

POST /upload

Example (curl)
curl -X POST "http://localhost:8000/upload" \
  -F "file=@example.pdf"

Response example
{
  "message": "File 'example.pdf' processed and stored successfully.",
  "chunks": 42
}

ğŸ” Query Your Documents

GET /query?query=your question

Example
curl "http://localhost:8000/query?query=What is the summary of section 2?"

Example response
{
  "query": "What is the summary of section 2?",
  "response": "Section 2 discusses..."
}

ğŸ§  Architecture Overview
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   PDF Upload   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  LlamaParse    â”‚ â†’ Markdown
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ SentenceSplitterâ”‚ â†’ chunks
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ OpenAI Embeddingâ”‚ â†’ vectors
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Qdrant      â”‚ (vector store)
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ GPT-4o Query   â”‚ + context
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ Folder Structure
ğŸ“¦ pdf-rag-api
 â”£ ğŸ“„ main.py
 â”£ ğŸ“„ requirements.txt
 â”£ ğŸ“„ README.md
 â”— ğŸ“„ .env